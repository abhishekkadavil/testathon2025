name: AI Performance Testing

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  ai-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install requests openai pytest pygithub

      - name: Setup Java & Maven
        uses: actions/setup-java@v4
        with:
          java-version: "17"
          distribution: "temurin"
          
      - name: Check if app.py changed
        id: changes
        run: |
          git fetch origin ${{ github.base_ref }} --depth=1
          if git diff --name-only origin/${{ github.base_ref }} | grep -q "app.py"; then
            echo "app_changed=true" >> $GITHUB_OUTPUT
          else
            echo "app_changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate Gatling Tests using OpenAI
        if: steps.changes.outputs.app_changed == 'true'
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENROUTER_MODEL: ${{ vars.OPENROUTER_MODEL }}
        run: |
          python scripts/generate_gatling_tests.py
          echo "üî• AI-generated Gatling test for app.py changes"
          
      - name: Install HyperExecute CLI
        run: |
          curl -LO https://downloads.lambdatest.com/hyperexecute/linux/hyperexecute
          chmod +x hyperexecute
          mv hyperexecute /usr/local/bin/hyperexecute

      - name: Provide HyperExecute Credentials
        env:
          LT_USERNAME: ${{ secrets.LT_USERNAME }}
          LT_ACCESS_KEY: ${{ secrets.LT_ACCESS_KEY }}
        run: |
          echo "Configured LT Credentials"

      - name: Print hyperexecute.yaml with line numbers
        run: |
          nl -ba hyperexecute.yaml

      # üü¶ Trigger HyperExecute
      - name: Run Gatling on HyperExecute
        env:
          LT_USERNAME: ${{ secrets.LT_USERNAME }}
          LT_ACCESS_KEY: ${{ secrets.LT_ACCESS_KEY }}
        run: |
          set -e
          hyperexecute --config hyperexecute.yaml
          status=$?
          echo "Execution Status: $status"

          if [ $status -ne 0 ]; then
            echo "‚ùå Performance test failed ‚Äî blocking merge"
            exit 1
          else
            echo "‚úÖ Performance test passed"
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: generated-tests-results
          path: |
            src/test/scala/ai/GeneratedSimulation.scala

      # - name: AI Performance Review
      #   env:
      #     OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
      #     GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      #     OPENROUTER_MODEL: ${{ vars.OPENROUTER_MODEL }}
      #     GITHUB_REPOSITORY: ${{ github.repository }}
      #     PR_NUMBER: ${{ github.event.pull_request.number }}
      #   run: python tests/perf_review.py || echo "‚ö†Ô∏è Skipping AI performance review due to rate limit"      # - name: Force-fail for validation (quick, temporary)
